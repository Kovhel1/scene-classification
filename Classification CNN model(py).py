# -*- coding: utf-8 -*-
"""ВКР.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gFbq9rfin1cfMVKlZpNQsLTSuxJuT14Q

# Нейронная сеть для классификации сцен
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers.experimental.preprocessing import Normalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import utils
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing import image_dataset_from_directory
import matplotlib.pyplot as plt
from google.colab import files
# %matplotlib inline

"""## Загружаем данные
(можно загрузить и с kaggle)
просто zip папка с папками по классам, которые содержат изображения jpeg
"""

!wget https://www.dropbox.com/s/pnq8ej5c9ti1se7/intel_scene.zip?dl=1 -O intel_scene.zip

"""распаковываем архив unzip"""

#@title
!unzip intel_scene.zip

"""Посмотрим, какие еще каталоги с фотографиями есть в архиве (по количеству классов в наборе)"""

!ls seg_train/seg_train

"""**Набор данных для обучения**

image_dataset_from_directory. Она читает изображение, которое находится в каталоге и создаёт из них набор данных для обучения, автоматически проставляя метки классов. Метки классов ставятся в зависимости от того, в каком каталоге находится то или иное изображение. Это как раз наш случай. У нас 6 каталогов. В каждом каталоге находится изображение одного класса. 

Как работает утилита image_dataset_from_directory? Необходимо указать 
1) путь,в котором находится каталоги с изображениями разных классов
2) размер мини выборки, набор данных большой, он не поместится целиком в память, поэтому изображения будут считаться с диска мини выборками, за один раз с диска будет читаться 128 изображений
3) размер изображений. Здесь мы используем 128 на 128. Хотя мы используем предварительно обученную сеть VGG16, и она обучена на наборе данных ImageNet на распознавание изображений размером 224 на 224, но для переноса обучения использовать тот же самый размер изображений не обязательно. Поэтому мы можем
указать свой размер, здесь  128 на 128.
"""

train_dataset = image_dataset_from_directory('seg_train/seg_train',
                                             subset='training',
                                             seed=42,
                                             validation_split=0.1,
                                             batch_size=128,
                                             image_size=(128, 128))

"""В наборе данных Intel Scene Classification
есть только две части: набор данных для обучения и набор данных для тестирования. Поэтому нам нужно самим создать набор данных для проверки. Для этого мы снова воспользуемся возможностями Keras,при загрузке набора данных указываем параметр validation_split равняется 0,1. Это означает,
что набор данных для обучения будет разбит на две части: 90 процентов будет использоваться для обучения, 10 процентов для проверки. При загрузке набора данных мы указываем, какой поднабор будет создан. 
"""

validation_dataset = image_dataset_from_directory('seg_train/seg_train',
                                             subset='validation',
                                             seed=42,
                                             validation_split=0.1,
                                             batch_size=128,
                                             image_size=(128, 128))

class_names = train_dataset.class_names
class_names

"""Выведем имеющиеся изображения на экран."""

plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

"""**Набор данных для тестирования**"""

test_dataset = image_dataset_from_directory('seg_test/seg_test',
                                             shuffle=True,
                                             label_mode='int',
                                             batch_size=128,
                                             image_size=(128, 128))

test_dataset.class_names

"""Для каждого набора данных мы устанавливаем, так называемый, prefetch. О чём это
говорит? Так как набор данных большой и целиком не помещается в память, то необходимо загружать
его с диска с порциями. Если не указывать другие настройки, то Keras будет загружать данные с диска
по одной мини выборке. При этом много времени будет тратиться на то, чтобы данные загрузились
с диска, и только после этого они будут передаваться в нейронную сеть для обучения. Для того чтобы
повысить производительность Keras на центральном процессоре занимается тем, что загружает данные с
диска, которые понадобятся через несколько шагов обучения, которые помещаются в буфер. Буфер Keras
определяет автоматически. 
"""

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)

"""## Создаем составную нейронную сеть

Мы создаем нейронную сеть с помощью конструктора VGG16. Указываем, что хотим загрузить предварительно обученные веса на наборе данных ImageNet, но при этом указываем параметры include_top=False. Это означает, что будет загружена только свёрточная часть сети VGG16, а полносвязная часть, которая отвечает за классификацию, и на выходе из которой 1000 нейронов, по тысяче классов объектов ImageNet загружена не будет. Эту часть мы заменим на свою собственную. 

Так как мы используем не тот формат изображений, на которые решить она сеть VGG16 по умолчанию, то мы указываем размер изображений 128 на 128. 3 говорит о том, что изображение цветные, три канала: red, green, blue.
"""

vgg16_net = VGG16(weights='imagenet', 
                  include_top=False, 
                  input_shape=(128, 128, 3))

"""Нам необходимо запретить изменять веса в нейронной сети VGG16 во время обучения, чтобы эти веса, обученные на наборе данных ImageNet, не испортились при дообучении на нашем наборе данных. Для этого в флаг trainable нейронной сети устанавливаем значения False. """

vgg16_net.trainable = False

"""Теперь все готово к тому, чтобы создать составную сеть. 

Создаем ее с помощью модели класса Sequential. В качестве первого слоя добавляем слой Normalisation, этот слой обеспечивает, чтобы значения на входе в нейронную сеть были в диапазоне от нуля до единицы. 

Следующий шаг, который мы делаем, это добавляем в модель нашу предварительно
обученную сеть VGG16 в качестве отдельного слоя, Keras такое позволяет. 

После этого добавляем слой Flatten, который берет данные на выходе из свёрточной части VGG16, которые находятся в двумерном формате, и преобразует их в плоский формат. 

И вот эти три слоя – это наша классификационная часть, которую мы добавляем к свёрточной части предварительно обученной сети VGG16. Именно эти три слоя будут использоваться для классификации объектов из сцен набора данных Image на основе данных, которые выдаст свёрточная часть VGG16. Первый слой содержит 256 нейронов, затем слой Dropout с характеристикой 0,5, и на выходе полносвязный слой Dense, 6 нейронов, по количеству классов в наборе данных, и функция активации softmax.
"""

model = Sequential()
model.add(Normalization())
# Добавляем модель VGG16 в сеть как слой
model.add(vgg16_net)
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(6, activation='softmax'))

"""**Компилируем модель**

Стоит обратить внимание, что тут используется sparse_categorical_crossentropy. Это та же самая categorical_crossentropy, но с другим форматом вывода ответов (не one hot encoding, а номера классов).
"""

model.compile(loss='sparse_categorical_crossentropy',
              optimizer="adam",
              metrics=['accuracy'])

"""## Обучаем нейронную сеть

Так как мы используем наборы данных немножко в другом формате, которые нам создала утилита image_dataset_from_directory, здесь у нас нет отдельных
массивов для изображений и правильных ответов, а изображение и правильные ответы находятся вместе в наборе данных. 

В train_dataset находятся данные для обучения и правильные ответы, а в
validation_ dataset данные для проверки и правильные ответы для них. 

Также мы указываем количество эпох обучения 15. Размер мини выборки указывать не нужно, потому что мы указали его при создании наших datasets. Обучение одной эпохи  занимает  17 или 18 секунд.
"""

history = model.fit(train_dataset, 
                    validation_data=validation_dataset,
                    epochs=15)

"""## Оцениваем качетсво обучения сети"""

# Оцениваем качество обучения модели на тестовых данных
scores = model.evaluate(test_dataset, verbose=1)

print("Доля верных ответов на тестовых данных, в процентах:", round(scores[1] * 100, 4))

plt.plot(history.history['accuracy'], 
         label='Доля верных ответов на обучающем наборе')
plt.plot(history.history['val_accuracy'], 
         label='Доля верных ответов на проверочном наборе')
plt.xlabel('Эпоха обучения')
plt.ylabel('Доля верных ответов')
plt.legend()
plt.show()

plt.plot(history.history['loss'], 
         label='Ошибка на обучающем наборе')
plt.plot(history.history['val_loss'], 
         label='Ошибка на проверочном наборе')
plt.xlabel('Эпоха обучения')
plt.ylabel('Ошибка')
plt.legend()
plt.show()

"""## Тонкая настройка нейронной сети

Мы размораживаем последний свёрточный блок, и после того как выполнили разморозку слоев, то есть сделали так, что они могут обучаться. Нам нужно заново скомпилировать нейронную сеть. Обратите внимание, что здесь мы указываем в оптимизатор adam, и у него меньше lr, единица на десять в минус пятой (малая скорость обучения).

разморозка последнего сверточного слоя
"""

vgg16_net.trainable = True
trainable = False
for layer in vgg16_net.layers:
    if layer.name == 'block5_conv1':
        trainable = True
    layer.trainable = trainable

"""малая скорость обучения"""

model.compile(loss='sparse_categorical_crossentropy',
              optimizer=Adam(lr=1e-5), 
              metrics=['accuracy'])

"""тонкая настройка требует небольшого количества эпох"""

history = model.fit(train_dataset, 
                    validation_data=validation_dataset,
                    epochs=4)

"""## Оцениваем качетсво обучения сети"""

# Оцениваем качество обучения модели на тестовых данных
scores = model.evaluate(test_dataset, verbose=1)

print("Доля верных ответов на тестовых данных, в процентах:", round(scores[1] * 100, 4))

plt.plot(history.history['accuracy'], 
         label='Доля верных ответов на обучающем наборе')
plt.plot(history.history['val_accuracy'], 
         label='Доля верных ответов на проверочном наборе')
plt.xlabel('Эпоха обучения')
plt.ylabel('Доля верных ответов')
plt.legend()
plt.show()

"""## Сохраняем обученную нейронную сеть"""

model.save("intel_image_model.h5")

!ls

"""Сохраняем модель на локальный компьютер"""

files.download("intel_image_model.h5")

"""# Загружаем обученную нейронную сеть"""

files.upload()

model = "intel_image_model.h5"

# Оцениваем качество обучения модели на тестовых данных
scores = model.evaluate(test_dataset, verbose=1)

"""# Используем получившуюся нейронную сеть

Посмотрим данные получившейся нейронной сети
"""

model.summary()

"""Загружаем картинку"""

files.upload()

"""Просматриваем картинку"""

filename = 'кот.jpg'
img = image.load_img(filename, target_size=(128, 128))
plt.imshow(img)
plt.show()

"""Преобразуем картинку в массив"""

x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

"""Запускаем распознавание"""

prediction = model.predict(x)
prediction

"""Вспомним имеющиеся класссы. Можно уже посмотреть на степень, число с наименьшей степенью и будет самым вероятным классом."""

print("Название класса:", class_names)

"""Выведем результат в более удобном виде"""

pred =[prediction[0][0], prediction[0][1], prediction[0][2], prediction[0][3], prediction[0][4], prediction[0][5]]
print(pred)

for i in range(0, len(pred)):
    maximum = pred[0]
    maxi = 0
    for i in range(0, len(pred)):
        if pred[i] > maximum:
            maximum = pred[i]

    for i in range(0, len(pred)):
      if pred[i] == maximum:
        print(class_names[i])
        print(round(pred[i]*100, 4) , '%')
        pred[i] = -1
        break

"""Ответы даны в порядке от наиболее вероятных к менее вероятным."""